{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Machine Learning Systems - (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper functions to display a video or an image \n",
    "from IPython.display import HTML\n",
    "def display_video(src):\n",
    "    print('Source : '+src+ '?autoplay=1;modestbranding=1;rel=0')\n",
    "    return HTML('<iframe width=\"800\" height=\"400\" src=' + src + '?autoplay=1;modestbranding=1;rel=0 frameborder=\"0\" allowfullscreen></iframe>')\n",
    "\n",
    "def display_image(src):\n",
    "    print('Source : '+src)\n",
    "    return HTML('<img width=\"600\" height=\"300\" src=' + src + '></img>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Classification Problem ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependent vs Independent variables:\n",
    "\n",
    "1. **Independent Variables for classification** - These are also called features of our dataset. They are the variables which when varied can affect our target classes that we want to predict.\n",
    "2. **Dependent Variable for classification** - When your target variable has certain class labels, its a classification problem. For instance classifying pictures of dogs and cats or a tumour to be cancerous or non cancerous etc. You are not predicting a continuous quantity here but different classes.\n",
    "\n",
    "Lets take an example to understand it clearly :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> [Breast Cancer Diagnostic] </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two main classifications of tumors. One is known as benign and the other as malignant. A benign tumor is a tumor that does not invade its surrounding tissue or spread around the body. A malignant tumor is a tumor that may invade its surrounding tissue or spread around the body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source : https://www.verywellhealth.com/thmb/xnYC1DVmfPtwjWCEdO0HjSZbcBo=/1787x0/filters:no_upscale():max_bytes(150000):strip_icc():format(webp)/514240-article-img-malignant-vs-benign-tumor2111891f-54cc-47aa-8967-4cd5411fdb2f-5a2848f122fa3a0037c544be.png\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img width=\"600\" height=\"300\" src=https://www.verywellhealth.com/thmb/xnYC1DVmfPtwjWCEdO0HjSZbcBo=/1787x0/filters:no_upscale():max_bytes(150000):strip_icc():format(webp)/514240-article-img-malignant-vs-benign-tumor2111891f-54cc-47aa-8967-4cd5411fdb2f-5a2848f122fa3a0037c544be.png></img>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_image('https://www.verywellhealth.com/thmb/xnYC1DVmfPtwjWCEdO0HjSZbcBo=/1787x0/filters:no_upscale():max_bytes(150000):strip_icc():format(webp)/514240-article-img-malignant-vs-benign-tumor2111891f-54cc-47aa-8967-4cd5411fdb2f-5a2848f122fa3a0037c544be.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our target it to train a Logistic Regression model that can predict whether the cancer is benign (B) or malignant (M)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attribute Information:\n",
    "<br>1) ID number \n",
    "<br>2) Diagnosis (M = malignant, B = benign) \n",
    "<br>3-32) Ten real-valued features are computed for each cell nucleus: \n",
    "<br>a) radius (mean of distances from center to points on the perimeter) \n",
    "<br>b) texture (standard deviation of gray-scale values) \n",
    "<br>c) perimeter \n",
    "<br>d) area \n",
    "<br>e) smoothness (local variation in radius lengths) \n",
    "<br>f) compactness (perimeter^2 / area - 1.0) \n",
    "<br>g) concavity (severity of concave portions of the contour) \n",
    "<br>h) concave points (number of concave portions of the contour) \n",
    "<br>i) symmetry \n",
    "<br>j) fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "**`'Diagnosis'`** column is the **Dependent Variable or target column** because we want our algorithm to predict this class.\n",
    "\n",
    "**`'1,3-32'`** are your **Features or Independent Variables** which will help you predict the Benign/Malignant class. Vary any one of them and it is going to affect your Diagnostic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Machine Learning classifier model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will discuss about the Logistic Regression algorithm. Don't be confused by the name \"Logistic Regression\"; it is named that way for historical reasons and is actually an approach to classification problems, not regression problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of our output vector y being a continuous range of values, it will only be 'M' or 'B'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Famous Classification Task (Hands-On !)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Its time for you to build your first Classification model and run it on Titanic Survival prediction problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to load train and test sets and see the relevant details of the features yourself using pandas:\n",
    "\n",
    "Once you have made your model and are ready with your predictions save it to a csv file, upload it on KAGGLE. See what you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the Titanic data set '../data/train.csv' and '../data/test.csv' into separate dataframes and view the head of dataframe\n",
    "df = pd.read_csv('../Data/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# printing missing values in dataset\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replacing missing values with mean\n",
    "df.fillna(df.mean(), inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# printing missing values in dataset\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the features to a variable X. Make sure that you remove 'Age', 'Embarked', 'Fare' from X.\n",
    "X = df.drop(['Survived','Age','Embarked','Fare'],axis=1)\n",
    "# Load the dependent variable to y\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# View the head of X and y\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data=pd.read_csv(\"../Data/trainoriginal.csv\")\n",
    "X_test = pd.read_csv('../Data/testOriginal.csv')\n",
    "data_df = data.append(X_test)\n",
    "data_df['Title'] = data_df['Name']\n",
    "for name_string in data_df['Name']:\n",
    "    data_df['Title'] = data_df['Name'].str.extract('([A-Za-z]+)\\.', expand=True)\n",
    "mapping = {'Mlle': 'Miss', 'Major': 'Mr', 'Col': 'Mr', 'Sir': 'Mr', 'Don': 'Mr', 'Mme': 'Miss',\n",
    "          'Jonkheer': 'Mr', 'Lady': 'Mrs', 'Capt': 'Mr', 'Countess': 'Mrs', 'Ms': 'Miss', 'Dona': 'Mrs'}\n",
    "data_df.replace({'Title': mapping}, inplace=True)\n",
    "titles = ['Dr', 'Master', 'Miss', 'Mr', 'Mrs', 'Rev']\n",
    "for title in titles:\n",
    "    age_to_impute = data_df.groupby('Title')['Age'].median()[titles.index(title)]\n",
    "    data_df.loc[(data_df['Age'].isnull()) & (data_df['Title'] == title), 'Age'] = age_to_impute\n",
    "data['Age'] = data_df['Age'][:891]\n",
    "X_test['Age'] = data_df['Age'][891:]\n",
    "data_df.drop('Title', axis = 1, inplace = True)\n",
    "data_df['Family_Size'] = data_df['Parch'] + data_df['SibSp']\n",
    "data['Family_Size'] = data_df['Family_Size'][:891]\n",
    "X_test['Family_Size'] = data_df['Family_Size'][891:]\n",
    "data['Sex'].replace(['male','female'],[0,1],inplace=True)\n",
    "X_test['Sex'].replace(['male','female'],[0,1],inplace=True)\n",
    "data_df['Fare'].fillna(data_df['Fare'].median(), inplace = True)\n",
    "data_df['Farebin'] = pd.qcut(data_df['Fare'], 5)\n",
    "label = LabelEncoder()\n",
    "data_df['FareBin_Code'] = label.fit_transform(data_df['Farebin'])\n",
    "data['FareBin_Code'] = data_df['FareBin_Code'][:891]\n",
    "X_test['FareBin_Code'] = data_df['FareBin_Code'][891:]\n",
    "data_df['Agebin'] = pd.qcut(data_df['Age'], 4)\n",
    "label = LabelEncoder()\n",
    "data_df['AgeBin_Code'] = label.fit_transform(data_df['Agebin'])\n",
    "data['AgeBin_Code'] = data_df['AgeBin_Code'][:891]\n",
    "X_test['AgeBin_Code'] = data_df['AgeBin_Code'][891:]\n",
    "data_df['Last_Name'] = data_df['Name'].apply(lambda x: str.split(x, \",\")[0])\n",
    "data_df['Fare'].fillna(data_df['Fare'].mean(), inplace=True)\n",
    "DEFAULT_SURVIVAL_VALUE = 0.5\n",
    "data_df['Family_Survival'] = DEFAULT_SURVIVAL_VALUE\n",
    "for grp, grp_df in data_df[['Survived','Name', 'Last_Name', 'Fare', 'Ticket', 'PassengerId',\n",
    "                           'SibSp', 'Parch', 'Age', 'Cabin']].groupby(['Last_Name', 'Fare']):\n",
    "    \n",
    "    if (len(grp_df) != 1):\n",
    "        # A Family group is found.\n",
    "        for ind, row in grp_df.iterrows():\n",
    "            smax = grp_df.drop(ind)['Survived'].max()\n",
    "            smin = grp_df.drop(ind)['Survived'].min()\n",
    "            passID = row['PassengerId']\n",
    "            if (smax == 1.0):\n",
    "                data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 1\n",
    "            elif (smin==0.0):\n",
    "                data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 0\n",
    "                \n",
    "for _, grp_df in data_df.groupby('Ticket'):\n",
    "    if (len(grp_df) != 1):\n",
    "        for ind, row in grp_df.iterrows():\n",
    "            if (row['Family_Survival'] == 0) | (row['Family_Survival']== 0.5):\n",
    "                smax = grp_df.drop(ind)['Survived'].max()\n",
    "                smin = grp_df.drop(ind)['Survived'].min()\n",
    "                passID = row['PassengerId']\n",
    "                if (smax == 1.0):\n",
    "                    data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 1\n",
    "                elif (smin==0.0):\n",
    "                    data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 0\n",
    "data['Family_Survival'] = data_df['Family_Survival'][:891]\n",
    "X_test['Family_Survival'] = data_df['Family_Survival'][891:]\n",
    "X_test = X_test.drop(['Name','PassengerId','Age','SibSp','Parch','Ticket','Cabin','Embarked','Fare'],axis=1)\n",
    "X=data.drop(['Name','PassengerId','SibSp','Age','Parch','Ticket','Cabin','Embarked','Fare','Survived'],axis=1)\n",
    "y=data['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier #82.25 SVC 81.25 RFC 81 LR 82.25 GBC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "X = std_scaler.fit_transform(X)\n",
    "X_test = std_scaler.transform(X_test)\n",
    "clf1 = SVC(probability=True)\n",
    "clf2 = GradientBoostingClassifier()\n",
    "clf3 = RandomForestClassifier()\n",
    "clf4 = KNeighborsClassifier()\n",
    "clf5 = LogisticRegression(solver=\"lbfgs\")\n",
    "clf = VotingClassifier(estimators=[('SVC',clf1),('GBC',clf2),('RFC',clf3),('KNN',clf4),('LR',clf5)],n_jobs=-1,voting=\"soft\")\n",
    "params = {'SVC__C': range(1,10),'GBC__n_estimators':range(100,200),'RFC__n_estimators':range(150, 250),'KNN__n_neighbors':range(3,20),'LR__C': range(1,10)}\n",
    "hyperparam = {'C':range(1,20), 'kernel':['rbf','poly','sigmoid'], 'gamma':['auto','scale']}\n",
    "grid = GridSearchCV(estimator=clf1, param_grid=hyperparam, cv=10, n_jobs=-1, scoring=\"neg_log_loss\")\n",
    "grid = grid.fit(X, y)\n",
    "predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(n_neighbors=16),\n",
    "    SVC(probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(n_estimators=200),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    LogisticRegression(solver=\"lbfgs\"),\n",
    "    GridSearchCV(estimator=clf, param_grid=params, refit=True, cv=3, n_jobs=-1, scoring=\"neg_log_loss\")]\n",
    "\n",
    "sss = StratifiedKFold(n_splits=3)\n",
    "x1 = np.array(X)\n",
    "y1 = np.array(y)\n",
    "for train_index, test_index in sss.split(x1, y1):\n",
    "    X_train, X_t = x1[train_index], x1[test_index]\n",
    "    y_train, y_t = y1[train_index], y1[test_index]\n",
    "    \n",
    "    for clf1 in classifiers:\n",
    "        name = clf1.__class__.__name__\n",
    "        clf1.fit(X_train, y_train)\n",
    "        train_predictions = clf1.predict(X_t)\n",
    "        acc = accuracy_score(y_t, train_predictions)\n",
    "        print(name, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "passengerId = pd.read_csv('../Data/testOriginal.csv')['PassengerId']\n",
    "results = pd.DataFrame({\n",
    "    \"PassengerId\": passengerId,\n",
    "    \"Survived\": predictions})\n",
    "results.to_csv('Your_submission.csv', index=False)\n",
    "results = pd.DataFrame({\n",
    "    \"PassengerId\": passengerId,\n",
    "    \"Survived\": y_pred})\n",
    "results.to_csv('Your_submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import a Classifier of your own choice from the list below !\n",
    "1. LinearSVC()\n",
    "2. MLPClassifier()\n",
    "3. KNeighborsClassifier()\n",
    "4. SVC()\n",
    "5. DecisionTreeClassifier()\n",
    "6. RandomForestClassifier()\n",
    "7. ExtraTreeClassifier()\n",
    "8. LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an instance for the classifier\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the model on our X-train dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print the Accuracy score for your model, dont forget to import mertrics from sklearn library\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit results on Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading test file for Kaggle Submissions\n",
    "X_test_Kaggle = pd.read_csv('../Data/test.csv')\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# printing missing values in dataset\n",
    "print(X_test_Kaggle.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_Kaggle.fillna(X_test_Kaggle.mean(), inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# printing missing values in dataset\n",
    "print(X_test_Kaggle.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kaggle_predictions = clf.predict(X_test_Kaggle.drop(['Age','Embarked','Fare'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_ids = pd.read_csv('../Data/testOriginal.csv')\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"PassengerId\": X_test_ids['PassengerId'],\n",
    "    \"Survived\": kaggle_predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results.to_csv('Your_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations on successfully building your first Classification Model !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
